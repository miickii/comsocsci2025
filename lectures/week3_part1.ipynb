{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load authors dataset\n",
    "authors_df = pd.read_csv('files/researchers_data_2024.csv')\n",
    "# Filter authors with works between 5 and 5000\n",
    "filtered_authors = authors_df[(authors_df['Works Count'] >= 5) & (authors_df['Works Count'] <= 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "#############################################\n",
    "# UTILITY FUNCTIONS\n",
    "#############################################\n",
    "\n",
    "def batch_list(lst, batch_size):\n",
    "    \"\"\"Yield successive chunks of size batch_size from lst.\"\"\"\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i+batch_size]\n",
    "\n",
    "#############################################\n",
    "# API FETCH FUNCTIONS\n",
    "#############################################\n",
    "\n",
    "def fetch_works_for_batch(author_ids, per_page=200, sleep_time=0.2):\n",
    "    \"\"\"\n",
    "    Fetch works from OpenAlex for a batch of author IDs.\n",
    "    \n",
    "    Parameters:\n",
    "      - author_ids: list of author OpenAlex IDs (e.g. \"https://openalex.org/A123456789\")\n",
    "      - filter_params: additional filter string (e.g. \"cited_by_count:>10,authorship_count:<10\")\n",
    "      - per_page: number of works per page (max 200)\n",
    "      - sleep_time: pause between pages (to respect rate limits)\n",
    "      \n",
    "    Returns:\n",
    "      - List of work dictionaries.\n",
    "    \"\"\"\n",
    "    works_endpoint = \"https://api.openalex.org/works\"\n",
    "    all_works = []\n",
    "    # Build filter for author IDs (using the OR operator \"|\")\n",
    "    filter_query = \"authorships.author.id:\" + \"|\".join(author_ids)\n",
    "    filter_query += \",cited_by_count:>10,authors_count:<10\"\n",
    "    filter_query += \",concepts.id:\" + \"|\".join([\"https://openalex.org/C144024400\", \"https://openalex.org/C15744967\", \"https://openalex.org/C162324750\", \"https://openalex.org/C17744445\", \"https://openalex.org/C33923547\", \"https://openalex.org/C121332964\", \"https://openalex.org/C41008148\"])\n",
    "\n",
    "    cursor = \"*\"\n",
    "    while True:\n",
    "        params = {\n",
    "            \"filter\": filter_query,\n",
    "            \"per_page\": per_page,\n",
    "            \"cursor\": cursor,\n",
    "            \"select\": \"id,publication_year,cited_by_count,authorships,abstract_inverted_index,title,concepts\"\n",
    "        }\n",
    "        response = requests.get(works_endpoint, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching works for authors {author_ids}: {response.status_code}\")\n",
    "            break\n",
    "        data = response.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        all_works.extend(results)\n",
    "        meta = data.get(\"meta\", {})\n",
    "        next_cursor = meta.get(\"next_cursor\")\n",
    "        if not next_cursor:\n",
    "            break\n",
    "        cursor = next_cursor\n",
    "        time.sleep(sleep_time)\n",
    "    return all_works\n",
    "\n",
    "def fetch_works_for_authors(author_ids, batch_size=25, n_jobs=5):\n",
    "    \"\"\"\n",
    "    Given a list of author IDs, split them into batches and fetch works in parallel.\n",
    "    \n",
    "    Returns:\n",
    "      - List of work dictionaries.\n",
    "    \"\"\"\n",
    "    batches = list(batch_list(author_ids, batch_size))\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(fetch_works_for_batch)(batch) for batch in tqdm(batches, desc=\"Fetching works for authors\")\n",
    "    )\n",
    "    # Flatten list of lists\n",
    "    all_works = [work for sublist in results for work in sublist]\n",
    "    return all_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_authors_ids = filtered_authors[\"ID\"].tolist()\n",
    "len(filtered_authors_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching works for authors: 100%|██████████| 40/40 [00:35<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works fetched for IC2S2 authors: 33548\n"
     ]
    }
   ],
   "source": [
    "all_works = fetch_works_for_authors(filtered_authors_ids)\n",
    "print(f\"Total works fetched for IC2S2 authors: {len(all_works)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query\n",
    "https://api.openalex.org/works?filter=authorships.author.id:A5082130337|A5014647140,cited_by_count:>10,authors_count:<10,concepts.id:https://openalex.org/C144024400|https://openalex.org/C15744967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works after concept filtering: 12746\n"
     ]
    }
   ],
   "source": [
    "def filter_works_by_concepts(works, css_concepts, quantitative_concepts):\n",
    "    \"\"\"\n",
    "    Filter works to include only those that have at least one level-0 concept \n",
    "    from each of the following groups:\n",
    "      - Computational Social Science: e.g. Sociology, Psychology, Economics, Political Science\n",
    "      - Quantitative disciplines: e.g. Mathematics, Physics, Computer Science\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    # Pre-lowercase the concept names for easier comparison\n",
    "    css_concepts_lower = [c.lower() for c in css_concepts]\n",
    "    quantitative_concepts_lower = [q.lower() for q in quantitative_concepts]\n",
    "    \n",
    "    for work in works:\n",
    "        concepts = work.get(\"concepts\", [])\n",
    "        css_found = False\n",
    "        quantitative_found = False\n",
    "        for concept in concepts:\n",
    "            if concept.get(\"level\") == 0:\n",
    "                name = concept.get(\"display_name\", \"\").lower()\n",
    "                if name in css_concepts_lower:\n",
    "                    css_found = True\n",
    "                if name in quantitative_concepts_lower:\n",
    "                    quantitative_found = True\n",
    "        if css_found and quantitative_found:\n",
    "            filtered.append(work)\n",
    "    return filtered\n",
    "\n",
    "css_concepts = [\"Sociology\", \"Psychology\", \"Economics\", \"Political Science\"]\n",
    "quantitative_concepts = [\"Mathematics\", \"Physics\", \"Computer Science\"]\n",
    "filtered_works = filter_works_by_concepts(all_works, css_concepts, quantitative_concepts)\n",
    "print(f\"Total works after concept filtering: {len(filtered_works)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12746\n"
     ]
    }
   ],
   "source": [
    "authors_papers = []\n",
    "authors_abstracts = []\n",
    "\n",
    "for work in filtered_works:\n",
    "    # Extract author IDs from the \"authorships\" field\n",
    "    authors = [auth.get(\"author\", {}).get(\"id\") for auth in work.get(\"authorships\", []) if auth.get(\"author\", {}).get(\"id\")]\n",
    "    authors_papers.append({\n",
    "        \"id\": work.get(\"id\"),\n",
    "        \"publication_year\": work.get(\"publication_year\"),\n",
    "        \"cited_by_count\": work.get(\"cited_by_count\"),\n",
    "        \"author_ids\": authors\n",
    "    })\n",
    "    authors_abstracts.append({\n",
    "        \"id\": work.get(\"id\"),\n",
    "        \"title\": work.get(\"title\"),\n",
    "        \"abstract_inverted_index\": work.get(\"abstract_inverted_index\")\n",
    "    })\n",
    "\n",
    "print(len(authors_papers))\n",
    "authors_papers_df = pd.DataFrame(authors_papers)\n",
    "authors_abstracts_df = pd.DataFrame(authors_abstracts)\n",
    "\n",
    "authors_papers_df.to_csv(\"authors_papers.csv\", index=False)\n",
    "authors_abstracts_df.to_csv(\"authors_abstracts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 2: Collecting Data from IC2S2 Co-Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#authors_papers_df = pd.read_csv(\"authors_papers.csv\")\n",
    "authors_papers = authors_papers_df.to_dict(orient='records')\n",
    "for paper in authors_papers:\n",
    "    if isinstance(paper['author_ids'], str):\n",
    "        paper['author_ids'] = ast.literal_eval(paper['author_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique co-author IDs: 16912\n"
     ]
    }
   ],
   "source": [
    "all_author_ids_in_works = set()\n",
    "for paper in authors_papers:\n",
    "    for aid in paper[\"author_ids\"]:\n",
    "        all_author_ids_in_works.add(aid)\n",
    "\n",
    "# Identify co-author IDs by removing the IC2S2 authors\n",
    "authors_ids_set = set(filtered_authors_ids)\n",
    "coauthor_ids = list(all_author_ids_in_works - authors_ids_set)\n",
    "print(f\"Total unique co-author IDs: {len(coauthor_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Fetch Co-Author Details in Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://api.openalex.org/authors\"\n",
    "coauthors_data = []\n",
    "\n",
    "# Use a session to reuse connections\n",
    "with requests.Session() as session:\n",
    "    for id in coauthor_ids:\n",
    "        params = {\n",
    "            \"select\": \"id,display_name,works_api_url,summary_stats,works_count,last_known_institutions\"\n",
    "        }\n",
    "        \n",
    "        response = session.get(URL + f\"/{id}\", params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            results = response.json()\n",
    "            if results:\n",
    "                result = results\n",
    "                author_id = result.get('id', '')\n",
    "                display_name = result.get('display_name', '')\n",
    "                works_api_url = result.get('works_api_url', '')\n",
    "                works_count = result.get('works_count', 0)\n",
    "                h_index = result.get('summary_stats', 0).get('h_index', 0)\n",
    "                country_code = result.get('last_known_institutions', '')\n",
    "                if country_code:\n",
    "                    country_code = country_code[0].get('country_code', '')\n",
    "\n",
    "                # Append to list\n",
    "                coauthors_data.append({\n",
    "                    \"ID\": author_id,\n",
    "                    \"Name\": display_name,\n",
    "                    \"Works API URL\": works_api_url,\n",
    "                    \"Works Count\": works_count,\n",
    "                    \"H-Index\": h_index,\n",
    "                    \"Country Code\": country_code\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error fetching data for {id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for {id}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15442"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coauthors_df = pd.read_csv(\"coauthors.csv\")\n",
    "print(len(coauthors_df))\n",
    "filtered_coauthors_df = coauthors_df[(coauthors_df[\"Works Count\"] >= 5) & (coauthors_df[\"Works Count\"] <= 5000)]\n",
    "coauthor_ids = filtered_coauthors_df[\"ID\"].tolist()\n",
    "len(coauthor_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15442, 994, 16436)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coauthor_ids_set = set(coauthor_ids)\n",
    "author_ids_set = set(filtered_authors_ids)\n",
    "allowed_authors = author_ids_set.union(coauthor_ids_set)\n",
    "len(coauthor_ids_set), len(author_ids_set), len(allowed_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_ids_1 = coauthor_ids[:5000]\n",
    "coauthor_ids_2 = coauthor_ids[5000:10000]\n",
    "coauthor_ids_3 = coauthor_ids[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching works for authors: 100%|██████████| 200/200 [07:37<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works fetched for IC2S2 authors: 222380\n"
     ]
    }
   ],
   "source": [
    "coauthor_works_1 = fetch_works_for_authors(coauthor_ids_1)\n",
    "print(f\"Total works fetched for IC2S2 authors: {len(coauthor_works_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching works for authors: 100%|██████████| 200/200 [09:48<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works fetched for IC2S2 authors: 226306\n"
     ]
    }
   ],
   "source": [
    "coauthor_works_2 = fetch_works_for_authors(coauthor_ids_2)\n",
    "print(f\"Total works fetched for IC2S2 authors: {len(coauthor_works_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Fetching works for authors:  72%|███████▎  | 29/40 [56:58<21:36, 117.87s/it]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Fetching works for authors: 100%|██████████| 218/218 [10:07<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works fetched for IC2S2 authors: 243152\n"
     ]
    }
   ],
   "source": [
    "coauthor_works_3 = fetch_works_for_authors(coauthor_ids_3)\n",
    "print(f\"Total works fetched for IC2S2 authors: {len(coauthor_works_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691838"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coauthor_works = []\n",
    "all_coauthor_works.extend(coauthor_works_1)\n",
    "all_coauthor_works.extend(coauthor_works_2)\n",
    "all_coauthor_works.extend(coauthor_works_3)\n",
    "len(all_coauthor_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total works after concept filtering: 264199\n"
     ]
    }
   ],
   "source": [
    "filtered_coauthor_works = filter_works_by_concepts(all_coauthor_works, css_concepts, quantitative_concepts)\n",
    "print(f\"Total works after concept filtering: {len(filtered_coauthor_works)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_coauthors = list(allowed_authors)\n",
    "\n",
    "def filter_coauthor_ids(author_ids, allowed_set):\n",
    "    \"\"\"\n",
    "    Given a list of author IDs (e.g., \"https://openalex.org/A123456789\"),\n",
    "    keep only those whose ID part (after \"org/\") is in allowed_set.\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for aid in author_ids:\n",
    "        # Extract the ID part if the URL is provided\n",
    "        if aid in allowed_set:\n",
    "            filtered.append(aid)\n",
    "    return filtered\n",
    "\n",
    "coauthors_papers = []\n",
    "coauthors_abstracts = []\n",
    "\n",
    "for work in filtered_coauthor_works:\n",
    "    # Extract author IDs from the \"authorships\" field\n",
    "    authors = [auth.get(\"author\", {}).get(\"id\") for auth in work.get(\"authorships\", []) if auth.get(\"author\", {}).get(\"id\")]\n",
    "\n",
    "    filtered_ids = filter_coauthor_ids(authors, allowed_coauthors)\n",
    "\n",
    "    if len(filtered_ids) > 1:\n",
    "        coauthors_papers.append({\n",
    "            \"id\": work.get(\"id\"),\n",
    "            \"publication_year\": work.get(\"publication_year\"),\n",
    "            \"cited_by_count\": work.get(\"cited_by_count\"),\n",
    "            \"author_ids\": filtered_ids\n",
    "        })\n",
    "        coauthors_abstracts.append({\n",
    "            \"id\": work.get(\"id\"),\n",
    "            \"title\": work.get(\"title\"),\n",
    "            \"abstract_inverted_index\": work.get(\"abstract_inverted_index\")\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101488, 101488)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coauthors_papers), len(coauthors_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthors_papers_df = pd.DataFrame(coauthors_papers)\n",
    "coauthors_abstracts_df = pd.DataFrame(coauthors_abstracts)\n",
    "\n",
    "coauthors_papers_df.to_csv(\"coauthors_papers.csv\", index=False)\n",
    "coauthors_abstracts_df.to_csv(\"coauthors_abstracts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining authors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered authors papers: (12746, 4)\n",
      "authors abstracts: (12746, 3)\n",
      "Filtered co-authors papers: (101488, 4)\n",
      "Co-authors abstracts: (101488, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered authors papers:\", authors_papers_df.shape)\n",
    "print(\"authors abstracts:\", authors_abstracts_df.shape)\n",
    "print(\"Filtered co-authors papers:\", coauthors_papers_df.shape)\n",
    "print(\"Co-authors abstracts:\", coauthors_abstracts_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A) Combine authors: concatenate IC2S2 authors and co-authors dataframes and remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined authors dataset shape: (16436, 6)\n"
     ]
    }
   ],
   "source": [
    "combined_authors_df = pd.concat([filtered_authors, filtered_coauthors_df], ignore_index=True)\n",
    "combined_authors_df.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
    "combined_authors_df.to_csv(\"authors_combined.csv\", index=False)\n",
    "print(\"Combined authors dataset shape:\", combined_authors_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B) Combine papers: concatenate IC2S2 papers and co-authors papers, drop duplicate works,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "#     and remove papers with only one author.\n",
    "# Note: If your \"author_ids\" column is stored as a string (e.g., as a list repr), convert it back to list.\n",
    "def parse_author_ids(author_ids):\n",
    "    if isinstance(author_ids, str):\n",
    "        try:\n",
    "            return ast.literal_eval(author_ids)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return author_ids\n",
    "\n",
    "# Ensure the author_ids column is in list format for each paper.\n",
    "for df in [authors_papers_df, coauthors_papers_df]:\n",
    "    if df[\"author_ids\"].dtype == object:\n",
    "        df[\"author_ids\"] = df[\"author_ids\"].apply(parse_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined papers dataset shape: (43341, 4)\n"
     ]
    }
   ],
   "source": [
    "combined_papers_df = pd.concat([authors_papers_df, coauthors_papers_df], ignore_index=True)\n",
    "combined_papers_df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "# Remove papers with only one author\n",
    "#combined_papers_df = combined_papers_df[combined_papers_df[\"author_ids\"].apply(lambda x: len(x) > 1)]\n",
    "combined_papers_df.to_csv(\"papers_combined.csv\", index=False)\n",
    "print(\"Combined papers dataset shape:\", combined_papers_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C) Combine abstracts: simply concatenate and drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114234, 3)\n",
      "Combined abstracts dataset shape: (43341, 3)\n"
     ]
    }
   ],
   "source": [
    "combined_abstracts_df = pd.concat([authors_abstracts_df, coauthors_abstracts_df], ignore_index=True)\n",
    "print(combined_abstracts_df.shape)\n",
    "combined_abstracts_df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "combined_abstracts_df.to_csv(\"abstracts_combined.csv\", index=False)\n",
    "print(\"Combined abstracts dataset shape:\", combined_abstracts_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
